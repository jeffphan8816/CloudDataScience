{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6602df31-70fe-41b0-bed0-05b6d28f0b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt \n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from ipyleaflet import Map, Marker, LayerGroup\n",
    "from datetime import datetime\n",
    "from ipywidgets import interact \n",
    "import warnings\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "URL = 'http://172.26.135.52:9090/'\n",
    "HEADERS = {'HOST': 'fission'}\n",
    "METRIC = 'Particles'\n",
    "weather_columns = ['Temp', 'Humid', 'WindSpeed', 'Rain']\n",
    "\n",
    "def filter_metric(results: list[dict], metric: str, station: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Filter specific metric and add station tag\n",
    "    \n",
    "    @param results is the raw data from ES\n",
    "    @param metric is the metric to filter\n",
    "    @param station is the station number as a string\n",
    "    @return a list of dictionaries of data\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for result in results:\n",
    "        try:\n",
    "            if result['_source']['measure_name'] == metric:\n",
    "                out.append(result['_source'])\n",
    "        except:\n",
    "            continue\n",
    "    for o in out:\n",
    "        o['Station'] = station\n",
    "    return out\n",
    "\n",
    "def get_readings(station: str, metric: str, year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get the readings from a station for a specific metric\n",
    "\n",
    "    @param station is the station number to query\n",
    "    @param metric is the metric to filter\n",
    "    @param year is the year int\n",
    "    @return list of dicts of filtered data\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    # Get station location\n",
    "    ret = requests.get(os.path.join(URL, 'epa', str(station), '1000', '50'), headers=HEADERS, params={'year': str(year)})\n",
    "    # Load response as json\n",
    "    try:\n",
    "        epa_resp_data = json.loads(ret.text)\n",
    "        if epa_resp_data['Status'] == 200:\n",
    "            out.extend(epa_resp_data['Data'])\n",
    "        else:\n",
    "            return []\n",
    "    except:\n",
    "        return []\n",
    "    while 'Token' in epa_resp_data.keys() and epa_resp_data['Token'] != 'END' and len(epa_resp_data['Data']) != 0:\n",
    "        ret = requests.get(os.path.join(URL, 'stream', epa_resp_data['Token']), headers=HEADERS)\n",
    "        try:\n",
    "            epa_resp_data = json.loads(ret.text)\n",
    "            out.extend(epa_resp_data['Data'])\n",
    "        except:\n",
    "            break\n",
    "    return filter_metric(out, metric, station)\n",
    "\n",
    "def get_weather(station: str, year: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get the weather from a station for a given year range\n",
    "\n",
    "    @param station is the string of the station number\n",
    "    @param year is the year int\n",
    "    @return list of dicts of weather\n",
    "    \"\"\"\n",
    "    ret = requests.get(os.path.join(URL, 'weather', station, str(year), str(year + 1)), headers=HEADERS)\n",
    "    try:\n",
    "        weather_data_json = json.loads(ret.text)\n",
    "        if weather_data_json['Status'] == 200:\n",
    "            weather_data = weather_data_json['Data']\n",
    "            for item in weather_data:\n",
    "                item['Station'] = station\n",
    "            return weather_data\n",
    "    except:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def clean_data(epa_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a cleaned and combined DataFrame fo weather and EPA data.\n",
    "    Combine on station and date\n",
    "\n",
    "    @param epa_df is the DataFrame with epa data\n",
    "    @param weather_df is the DataFrame with weather data\n",
    "    @returns concatenated DataFrame\n",
    "    \"\"\"\n",
    "    epa_df['location'] = epa_df['location'].apply(lambda x: (x[0], x[1]))\n",
    "    epa_df = epa_df.drop_duplicates(subset=epa_df.columns.difference(['station']))\n",
    "    epa_df['start'] = epa_df['start'].apply(lambda x: datetime.strptime(x.split('T')[0], '%Y-%m-%d'))\n",
    "    epa_df['end'] = epa_df['end'].apply(lambda x: datetime.strptime(x.split('T')[0], '%Y-%m-%d'))\n",
    "    epa_df['Date'] = epa_df['start']\n",
    "    epa_df[METRIC] = epa_df['value']\n",
    "    weather_df['Date'] = weather_df['Date'].apply(lambda x: datetime.strptime(x.split('T')[0], '%d/%m/%Y'))\n",
    "    weather_df['Max Temp'] = pd.to_numeric(weather_df['Max Temp'])\n",
    "    weather_df['Min Temp'] = pd.to_numeric(weather_df['Min Temp'])\n",
    "    weather_df['Max Humid'] = pd.to_numeric(weather_df['Max Humid'])\n",
    "    weather_df['Min Humid'] = pd.to_numeric(weather_df['Min Humid'])\n",
    "    weather_df['Min Humid'] = pd.to_numeric(weather_df['Min Humid'])\n",
    "    weather_df['Rain'] = pd.to_numeric(weather_df['Rain'])\n",
    "    weather_df['WindSpeed'] = pd.to_numeric(weather_df['WindSpeed'])\n",
    "    weather_df['Temp'] = (weather_df['Min Temp'] + weather_df['Max Temp']) / 2.0\n",
    "    weather_df['Humid'] = (weather_df['Min Humid'] + weather_df['Max Humid']) / 2.0\n",
    "    weather_df = weather_df[weather_df['Temp'] > -50]\n",
    "    weather_df = weather_df[weather_df['WindSpeed'] >= 0]\n",
    "    weather_df = weather_df[weather_df['Humid'] >= 0]\n",
    "    weather_df = weather_df[weather_df['Rain'] >= 0]\n",
    "    combined_df = pd.merge(epa_df, weather_df, on=['Date', 'Station'], how='inner')\n",
    "    out_cols = weather_columns.copy()\n",
    "    out_cols.append(METRIC)\n",
    "    \n",
    "    return combined_df[out_cols]\n",
    "\n",
    "def update_user(coord):\n",
    "    \"\"\"\n",
    "    Build the data display for a given location\n",
    "\n",
    "    @param coord is the coordinates to use\n",
    "    \"\"\"\n",
    "    # First find the closest station\n",
    "    ret = requests.get(os.path.join(URL, 'stations', str(coords[1]), str(coords[0])))\n",
    "    data = json.loads(ret.text)\n",
    "    if data['Status'] == 200:\n",
    "        station = str(data['Data']['Station ID'])\n",
    "        # Get weather predixtion based on weather\n",
    "        ret = requests.get(os.path.join(URL, 'current-weather'), params={'id': station}, headers=HEADERS)\n",
    "        weather_json = json.loads(ret.text)\n",
    "        if weather_json['Status'] == 200:\n",
    "            try:\n",
    "                # Build query\n",
    "                weather = {}\n",
    "                weather['Temp'] = weather_json['Data']['Temp']\n",
    "                weather['Humid'] = weather_json['Data']['Humid']\n",
    "                weather['Rain'] = weather_json['Data']['Rain']\n",
    "                weather['WindSpeed'] = weather_json['Data']['Wind Speed (km/h)']\n",
    "                query = ''\n",
    "                for field in weather_columns:\n",
    "                    query += str(weather[field]) + ','\n",
    "                ret = requests.get(os.path.join(URL, 'models', 'epa_model'), params={'predictors': query[:-1]}, headers=HEADERS)\n",
    "                print(\"Particle Prediction: \", str(json.loads(ret.text)['prediction']), 'Micro Grams per Cubic Meter')\n",
    "            except:\n",
    "                print('Error Getting Prediction')\n",
    "        else :\n",
    "            print('Error Getting Local Weather')\n",
    "            \n",
    "        # Get last year readings\n",
    "        year = datetime.now().year\n",
    "        epa_list = get_readings(station, METRIC, year)\n",
    "        weather_list = get_weather(station, year)\n",
    "        if len(epa_list) == 0 or len(weather_list) == 0:\n",
    "            print('Not Enough Data, Please Choose New Location')\n",
    "            return\n",
    "        # Put into DataFrames then combine\n",
    "        epa_readings = pd.DataFrame.from_records(epa_list)\n",
    "        weather_readings = pd.DataFrame.from_records(weather_list)\n",
    "        combined_df = clean_data(epa_readings, weather_readings)\n",
    "\n",
    "        # Display data\n",
    "        def display(Metric: str):\n",
    "            \"\"\"\n",
    "            Display the scatter plot\n",
    "            \"\"\"\n",
    "            plt.scatter(combined_df[Metric], combined_df[METRIC])\n",
    "            # Make tik marks\n",
    "            x_range = abs(combined_df[Metric].max() - combined_df[Metric].min())\n",
    "            start_x = combined_df[Metric].min()\n",
    "            interval = x_range / 8.0\n",
    "            ticks = []\n",
    "            for n in range(9):\n",
    "                ticks.append(start_x + n * interval)\n",
    "            plt.xticks(ticks)\n",
    "            plt.xlabel(Metric)\n",
    "            plt.ylabel(METRIC)\n",
    "            plt.show()\n",
    "            return Metric\n",
    "        interact(display, Metric=weather_columns)\n",
    "\n",
    "        # Create a correlation matrix\n",
    "        correlation_columns = weather_columns.copy()\n",
    "        correlation_columns.append(METRIC)\n",
    "        corr_table_pers = combined_df[correlation_columns].corr(method='pearson')\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(corr_table_pers, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title('Correlation Matrix')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2690e9a-8500-423e-baec-f0e817d6b712",
   "metadata": {},
   "source": [
    "# Please Choose a Location (Limited to Victoria, but Not All of Victoria Has Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "051f7bf8-afc6-499c-b40a-0aad1aa42bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe940f29a49548caa314adf5fc76777f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-38.0, 145.0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c71dc2155994d09b82d57dc7dfa874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an output widget to capture interaction\n",
    "out = Output()\n",
    "\n",
    "# Create a map centered at Australia's approximate center\n",
    "center = (-38., 145.)\n",
    "m = Map(center=center, zoom=6)\n",
    "\n",
    "# Create a layer group to hold the marker\n",
    "marker_layer = LayerGroup()\n",
    "m.add_layer(marker_layer)\n",
    "coords = None\n",
    "\n",
    "# Handle marker placement\n",
    "def handle_interaction(**kwargs):\n",
    "    global coords, marker\n",
    "    if kwargs.get('type') == 'click':\n",
    "        coords = kwargs.get('coordinates')\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            update_user(coords)\n",
    "\n",
    "        marker_layer.clear_layers()\n",
    "        # Add a new draggable marker at the clicked location\n",
    "        marker = Marker(location=coords, draggable=True)\n",
    "        marker.observe(handle_drag, names='location')\n",
    "        marker_layer.add_layer(marker)\n",
    "\n",
    "# Handle marker dragging - otherwise the coords will not update\n",
    "def handle_drag(event):\n",
    "    global coords\n",
    "    coords = event['new']\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        update_user(coords)\n",
    "# Attach the function to the map\n",
    "m.on_interaction(handle_interaction)\n",
    "\n",
    "# Display the map with the selector widget\n",
    "display(m, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9337444-c825-41dd-98a1-b4208f74bbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
