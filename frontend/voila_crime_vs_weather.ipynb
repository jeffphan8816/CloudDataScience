{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipyleaflet import Map, Marker\n",
    "\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "RUN_FROM = 'uni_wifi' #'bastion'\n",
    "\n",
    "if RUN_FROM == 'bastion' : URL, HEADERS = 'http://fission:31001/', None\n",
    "if RUN_FROM == 'uni_wifi': URL, HEADERS =  'http://172.26.135.52:9090/', {'HOST': 'fission'}\n",
    "\n",
    "WEATHER_NUM_COL = ['UV', 'Min Temp', 'Max Temp', 'WindSpeed', 'Min Humid', 'Max Humid', 'Rain', 'Pan-Rain', 'Evapo-Rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_to_pd(station_id: str, start_year: int, end_year: int, verb=False) -> pd.DataFrame:\n",
    "    resp_dict = json.loads(requests.get(URL+f'weather/{station_id}/{start_year}/{end_year}', headers=HEADERS).text)\n",
    "    data = resp_dict['Data']\n",
    "    if verb : print(f'Called weather api, fetched {len(data)} lines')\n",
    "    return pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_to_pd(api: str, station_id: str, size: int, radius_km: int, verb=False) -> pd.DataFrame:\n",
    "    resp_dict = json.loads(requests.get(URL+api+f'/{station_id}/{size}/{radius_km}', headers=HEADERS).text)\n",
    "\n",
    "    count=0\n",
    "    status, token, new_data = resp_dict['Status'], resp_dict['Token'], resp_dict['Data']\n",
    "    data = [new_data[i]['_source'] for i in range(len(new_data))]\n",
    "    if verb : print(f'Called {api} api, fetched {len(new_data)} lines')\n",
    "\n",
    "\n",
    "    while (status == 200) and (new_data != []) :\n",
    "        count+=1\n",
    "        resp_dict = json.loads(requests.get(URL+f'stream/'+token, headers=HEADERS).text)\n",
    "        status, token, new_data = resp_dict['Status'], resp_dict['Token'], resp_dict['Data']\n",
    "        if verb : print(f'Called stream {count} times, fetched {len(new_data)} new lines')\n",
    "        data += [new_data[i]['_source'] for i in range(len(new_data))]\n",
    "\n",
    "    if verb: print(f'Fetched a total of {len(data)}lines')\n",
    "    return pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_weather_pd(df_weather_full):\n",
    "    df_weather = df_weather_full.copy()\n",
    "\n",
    "    for col in WEATHER_NUM_COL:\n",
    "        df_weather[col] = pd.to_numeric(df_weather[col])\n",
    "\n",
    "    df_weather = df_weather.rename(columns={'Date':'date'})\n",
    "    df_weather['date'] = pd.to_datetime(df_weather['date'], format='%d/%m/%Y').dt.date\n",
    "    df_weather = df_weather.drop(columns=['created_at','source', 'Station Name'])\n",
    "\n",
    "    return df_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_crime_df(df_crime_full):\n",
    "    df_crime = df_crime_full.groupby(['reported_date', 'description_1'])['offence_count'].sum().reset_index()\n",
    "\n",
    "    df_crime = df_crime.rename(columns={'reported_date':'date'})\n",
    "    df_crime['date'] = pd.to_datetime(df_crime['date']).dt.date\n",
    "\n",
    "    return df_crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to IISTGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/isitsafe_banner.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General trends over the last year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Weather impacts crime in your area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154dff212de44d9996299ec897faa859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-38.0, 145.0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_oâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose your position\n",
    "center = (-38., 145.)\n",
    "mm = Map(center=center, zoom=6)\n",
    "marker = Marker(location=center, draggable=True)\n",
    "mm.add(marker)\n",
    "display(mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9046f1dae72b404c84a5a4a0e4d50ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=50.0, description='Radius in km'),))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose your radius for study\n",
    "slider = widgets.FloatSlider(description='Radius in km')\n",
    "slider.observe(compute, 'value')\n",
    "slider.value = 50\n",
    "widgets.VBox([slider])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Coordinates: [-38.0, 145.0]\n",
      "Chosen study radius: 50.0 km\n",
      "Closest weather station name FAWKNER BEACON\n",
      "Study conducted over the last ten years\n"
     ]
    }
   ],
   "source": [
    "# Summary of the study\n",
    "LOCATION = marker.location\n",
    "RADIUS = slider.value\n",
    "\n",
    "resp = requests.get(URL+f'stations/{LOCATION[1]}/{LOCATION[0]}').json()\n",
    "STATION_ID = resp['Data']['Station ID']\n",
    "\n",
    "print(f'Chosen Coordinates: {LOCATION}')\n",
    "print(f'Chosen study radius: {RADIUS} km')\n",
    "print(f'Closest weather station name {resp[\"Data\"][\"Station Name\"]}')\n",
    "print(f'Study conducted over the last ten years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching data and computing \n",
    "df_weather_full = weather_to_pd(station_id=STATION_ID, start_year =2014, end_year=2024,verb=True)\n",
    "df_weather = clean_weather_pd(df_weather_full=)\n",
    "df_crime_full = get_stream_to_pd(api='crime', station_id=STATION_ID, size=8000, radius_km=RADIUS, verb=True)\n",
    "df_crime = clean_crime_df(df_crime_full=)\n",
    "df = pd.merge(df_weather, df_crime, on='date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model_pers = LinearRegression()\n",
    "lin_model_pers.fit(df_pers.drop(columns='offence_count').values, df_pers['offence_count'])\n",
    "pd.DataFrame({'Predictors': df_pers.columns[:-1], 'Coefficient': lin_model_pers.coef_})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
