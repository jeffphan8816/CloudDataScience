{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "RUN_FROM = 'uni_wifi' #'bastion'\n",
    "\n",
    "if RUN_FROM == 'bastion' : URL, HEADERS = 'http://fission:31001/', None\n",
    "if RUN_FROM == 'uni_wifi': URL, HEADERS =  'http://172.26.135.52:9090/', {'HOST': 'fission'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_to_pd(station_id: str, start_year: int, end_year: int, verb=False) -> pd.DataFrame:\n",
    "    resp_dict = json.loads(requests.get(URL+f'weather/{station_id}/{start_year}/{end_year}', headers=HEADERS).text)\n",
    "    data = resp_dict['Data']\n",
    "    if verb : print(f'Called weather api, fetched {len(data)} lines')\n",
    "    return pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stream_to_pd(api: str, station_id: str, size: int, radius_km: int, verb=False) -> pd.DataFrame:\n",
    "    resp_dict = json.loads(requests.get(URL+api+f'/{station_id}/{size}/{radius_km}', headers=HEADERS).text)\n",
    "\n",
    "    count=0\n",
    "    status, token, new_data = resp_dict['Status'], resp_dict['Token'], resp_dict['Data']\n",
    "    data = [new_data[i]['_source'] for i in range(len(new_data))]\n",
    "    if verb : print(f'Called {api} api, fetched {len(new_data)} lines')\n",
    "\n",
    "\n",
    "    while (status == 200) and (new_data != []) :\n",
    "        count+=1\n",
    "        resp_dict = json.loads(requests.get(URL+f'stream/'+token, headers=HEADERS).text)\n",
    "        status, token, new_data = resp_dict['Status'], resp_dict['Token'], resp_dict['Data']\n",
    "        if verb : print(f'Called stream {count} times, fetched {len(new_data)} new lines')\n",
    "        data += [new_data[i]['_source'] for i in range(len(new_data))]\n",
    "\n",
    "    if verb: print(f'Fetched a total of {len(data)}lines')\n",
    "    return pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joined data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_full = weather_to_pd(station_id='95003', start_year =2014, end_year=2019, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = df_weather_full.copy()\n",
    "\n",
    "weather_num_cols = ['UV', 'Min Temp', 'Max Temp', 'WindSpeed', 'Min Humid', 'Max Humid', 'Rain', 'Pan-Rain', 'Evapo-Rain']\n",
    "\n",
    "for col in weather_num_cols:\n",
    "    df_weather[col] = pd.to_numeric(df_weather[col])\n",
    "\n",
    "df_weather = df_weather.rename(columns={'Date':'date'})\n",
    "df_weather['date'] = pd.to_datetime(df_weather['date'], format='%d/%m/%Y').dt.date\n",
    "df_weather = df_weather.drop(columns=['created_at','source', 'Station Name'])\n",
    "\n",
    "df_weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_full = get_stream_to_pd(api='crime', station_id='95003', size=8000, radius_km=800, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_full.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = df_crime_full.groupby(['reported_date', 'description_1'])['offence_count'].sum().reset_index()\n",
    "\n",
    "df_crime = df_crime.rename(columns={'reported_date':'date'})\n",
    "df_crime['date'] = pd.to_datetime(df_crime['date']).dt.date\n",
    "\n",
    "df_crime.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_weather, df_crime, on='date', how='inner')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers = df[df['description_1'] == 'OFFENCES AGAINST THE PERSON']\n",
    "df_pers = df_pers.drop(columns=['description_1', 'date'])\n",
    "df_pers.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model_pers = LinearRegression()\n",
    "lin_model_pers.fit(df_pers.drop(columns='offence_count').values, df_pers['offence_count'])\n",
    "pd.DataFrame({'Predictors': df_pers.columns[:-1], 'Coefficient': lin_model_pers.coef_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_lin_model_pers = LinearRegression()\n",
    "sub_lin_model_pers.fit(df_pers[['Evapo-Rain']].values, df_pers['offence_count'])\n",
    "\n",
    "# plt.scatter(df_pers[['Evapo-Rain','offence_count']].values)\n",
    "plt.scatter(df_pers['Evapo-Rain'],df_pers['offence_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_table_pers = df_pers.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_table_pers, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = 'Evapo-Rain'  # 'UV', 'Min Temp', 'Max Temp', 'WindSpeed', 'Min Humid', 'Max Humid', 'Rain', 'Pan-Rain', 'Evapo-Rain'\n",
    "r, p_value = pearsonr(df_pers[predictor], df_pers['offence_count'])\n",
    "print(f'With a correlation of {r}, the p-value associated to H0:\"There is no correlation\" is {p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Sending lin_model_perss to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'linear_model_pers_{REGION}.pkl', 'wb') as f:\n",
    "    pickle.dump(lin_model_pers, f)\n",
    "\n",
    "# Send the pickle file to the API via POST request\n",
    "'\n",
    "files = {'model': open('linear_model.pkl', 'rb')}\n",
    "response = requests.post(URL, headers=HEADERS, files=files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
